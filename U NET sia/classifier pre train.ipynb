{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxI4LLcnZqRN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY3XUmVsqEM1"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Input,Flatten,Reshape,AveragePooling2D,Dropout,LayerNormalization, ReLU,concatenate,Cropping2D, BatchNormalization\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input,Dropout, ReLU,BatchNormalization,Concatenate,LeakyReLU,Identity\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "font_path = '../dados/targa/Targa.ttf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhNVxxbZ6qj",
        "outputId": "1ac5b4e0-1aad-4cd1-f1a3-70c23c374ef6"
      },
      "outputs": [],
      "source": [
        "!wget  -nc https://www.dropbox.com/scl/fi/uaiyxp0t2l8hfcszfadtj/dados.zip?rlkey=lnqcb79vbu8j6cdbfgofogius&dl=1\n",
        "!unzip -n -q dados.zip?rlkey=lnqcb79vbu8j6cdbfgofogius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-owKNFD5ah24",
        "outputId": "adecb30f-3918-47dd-f02d-b8c94163f530"
      },
      "outputs": [],
      "source": [
        "image_path = '../dados/CAPTCHA-10k/treinamento'\n",
        "def generate_df(image_path):\n",
        "  label_path = '../dados/CAPTCHA-10k/labels10k'\n",
        "\n",
        "  jpg_files = [f for f in os.listdir(image_path) if f.endswith('.jpg')]\n",
        "  jpg_files.sort()\n",
        "  data = []\n",
        "\n",
        "  for jpg_file in jpg_files:\n",
        "      txt_file = os.path.splitext(jpg_file)[0] + '.txt'\n",
        "      txt_file_path = os.path.join(label_path, txt_file)\n",
        "\n",
        "      if os.path.exists(txt_file_path):\n",
        "          with open(txt_file_path, 'r') as file:\n",
        "              txt_content = file.read().strip()\n",
        "\n",
        "          data.append({'jpg_file': jpg_file, 'txt_content': txt_content})\n",
        "  return pd.DataFrame(data)\n",
        "\n",
        "df = generate_df(image_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = np.unique(list(df['txt_content'].sum()))\n",
        "vocab = list(vocab)\n",
        "np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGKSD3tFpvIH"
      },
      "outputs": [],
      "source": [
        "def generate_clean_captcha(text):\n",
        "    # Fixed parameters\n",
        "    size = (180, 50)  # Change size to (height, width)\n",
        "    font_size = 24\n",
        "    num_parts = 6\n",
        "\n",
        "    # Create a blank white image\n",
        "    image = Image.new('L', size, 255)  # 'L' mode for grayscale\n",
        "\n",
        "    # Load the custom font\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "    # Create a drawing context\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Calculate positions for each part\n",
        "    part_width = size[0] / num_parts\n",
        "    horizontal_positions = [int(part_width * i + part_width / 2) for i in range(num_parts)]\n",
        "    horizontal_positions = horizontal_positions[:len(text)]  # Adjust to the length of the text\n",
        "\n",
        "    # Calculate y position to center the text vertically\n",
        "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    text_height = text_bbox[3] - text_bbox[1]\n",
        "    text_y = (size[1] - text_height) // 2\n",
        "\n",
        "    # Draw each letter at the calculated position\n",
        "    for char, x in zip(text, horizontal_positions):\n",
        "        char_bbox = draw.textbbox((0, 0), char, font=font)\n",
        "        char_width = char_bbox[2] - char_bbox[0]\n",
        "        char_x = x - char_width // 2  # Center the character horizontally within its part\n",
        "        draw.text((char_x, text_y), char, font=font, fill=0)\n",
        "\n",
        "    # Convert to numpy array if needed for further processing with OpenCV\n",
        "    captcha_image = np.array(image)\n",
        "\n",
        "    return captcha_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_X_Y(image_path):\n",
        "  df = generate_df(image_path)\n",
        "\n",
        "  num_classes = len(vocab)\n",
        "  char_to_index = {char: idx for idx, char in enumerate(vocab)}\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for text in df['txt_content']:\n",
        "    x = generate_clean_captcha(text[:6])\n",
        "    interval = [0,30,60,90,120,150,180]\n",
        "    for i in range(len(interval)-1):\n",
        "        fake_img = x[:,interval[i]:interval[i+1]]\n",
        "        y = np.zeros((1,num_classes))\n",
        "        y[0,char_to_index[text[i]]] = 1\n",
        "        X.append(fake_img)\n",
        "        Y.append(y)\n",
        "\n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "\n",
        "  X = (X.astype('float32') - 127.5)  / 127.5\n",
        "\n",
        "  X = X.reshape(-1,50,30,1)\n",
        "  Y = Y.reshape(-1,num_classes)\n",
        "  return X,Y\n",
        "\n",
        "X,Y = generate_X_Y('../dados/CAPTCHA-10k/treinamento')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit(X)\n",
        "batch_size = 8\n",
        "augmented_data_generator = datagen.flow(X, Y, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Camada Convolution-BatchNorm-ReLu\n",
        "def CK(filters, kernel_size=(4, 4), strides=(2, 2), padding='same', use_batch_norm=True, downsample=True):\n",
        "    '''\n",
        "        filters: quantidade de filtros\n",
        "        kernel_size 3x3 | strides 1x1 | padding same | sao constantes durante o codigo\n",
        "        use_batch_norm ->   indica quando devemos usar BatchNormalization, em caso de negativo, a camada se torna a Identidade\n",
        "        downsample ->       indica se a dimensao deve aumentar ou diminuir \n",
        "    '''\n",
        "\n",
        "    # Esse chavemento usando  if ternario serve para selecionar as camadas com base nos atributos\n",
        "    conv = Conv2D               if downsample       else Conv2DTranspose\n",
        "    norm = BatchNormalization   if use_batch_norm   else Identity\n",
        "    actf = LeakyReLU(0.2)       if downsample       else ReLU()\n",
        "    # alpha de 0.2 na LeakyReLU foi definido no paper original\n",
        "\n",
        "    # Com o chaveamento pronto, a camada pode ser montada sequencialmente\n",
        "    def layer(x):\n",
        "        x = conv(filters, kernel_size, strides=strides, padding=padding)(x)\n",
        "        x = norm()(x)\n",
        "        x = actf(x)\n",
        "        return x\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discriminator(output_nc, ngf, num_downsample=3):\n",
        "\n",
        "    # O discriminador por sua vez, recebe a entrada e a saida do modelo, tentando assim decidir se aquilo 'e real ou nao\n",
        "    tar = Input(shape=[50, 30, output_nc], name='target_image')\n",
        "\n",
        "    # Initial convolutional layers # SEM BATCH NORM !\n",
        "    x = CK(ngf,use_batch_norm=False)(tar)\n",
        "\n",
        "    # Contracting path\n",
        "    for i in range(num_downsample):\n",
        "        x = CK(ngf*(2**(i+1)))(x)\n",
        "    \n",
        "    # Por fim, a patchGan gera uma classificao binaria por patch, o tamanho do patch eh definido pelo num_downsample. Quanto maior, menor a area de recepcao\n",
        "    # Por exemplo num_downsample = 4 faz com que o discriminador classifique blocos de 16x16\n",
        "    x = Conv2D(ngf//2, (1, 1),activation='ReLU')(x)\n",
        "    x = Flatten()(x)\n",
        "    # x = Dense(64,activation=\"ReLU\")(x)\n",
        "    x = Dense(37,activation=\"softmax\")(x)\n",
        "    return Model(inputs=tar, outputs=x)\n",
        "\n",
        "classifier = discriminator(1,64,2)\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StopTrainingCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('accuracy') == 1.0:\n",
        "            print(\"\\nReached 100% accuracy, stopping training!\")\n",
        "            self.model.stop_training = True\n",
        "        \n",
        "        if logs.get('val_accuracy') == 1.0:\n",
        "            print(\"\\nReached 100% accuracy on val, stopping training!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'classifier_pre_trained_best.tf',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_training_callback = StopTrainingCallback()\n",
        "classifier.fit(augmented_data_generator,steps_per_epoch=len(X) // batch_size, epochs=500, \n",
        "               callbacks=[stop_training_callback,checkpoint],\n",
        "               validation_data=(X, Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier.save(\"classifier_pre_trained.tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier.evaluate(X,Y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
