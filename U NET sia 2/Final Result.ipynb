{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxI4LLcnZqRN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY3XUmVsqEM1"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Input,Flatten,Reshape,AveragePooling2D,Dropout,LayerNormalization, ReLU,concatenate,Cropping2D, BatchNormalization\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-owKNFD5ah24",
        "outputId": "adecb30f-3918-47dd-f02d-b8c94163f530"
      },
      "outputs": [],
      "source": [
        "image_path = '../dados/CAPTCHA-10k/teste'\n",
        "def generate_df(image_path):\n",
        "  label_path = '../dados/CAPTCHA-10k/labels10k'\n",
        "\n",
        "  jpg_files = [f for f in os.listdir(image_path) if f.endswith('.jpg')]\n",
        "  jpg_files.sort()\n",
        "  data = []\n",
        "\n",
        "  for jpg_file in jpg_files:\n",
        "      txt_file = os.path.splitext(jpg_file)[0] + '.txt'\n",
        "      txt_file_path = os.path.join(label_path, txt_file)\n",
        "\n",
        "      if os.path.exists(txt_file_path):\n",
        "          with open(txt_file_path, 'r') as file:\n",
        "              txt_content = file.read().strip()\n",
        "\n",
        "          data.append({'jpg_file': jpg_file, 'txt_content': txt_content})\n",
        "  return pd.DataFrame(data)\n",
        "\n",
        "df = generate_df(image_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'A', 'B',\n",
        "       'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O',\n",
        "       'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "  kernel  = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
        "  img     = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "  _, img  = cv2.threshold(img, 90, 255, cv2.THRESH_BINARY)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpd9GwIhpKMe"
      },
      "outputs": [],
      "source": [
        "def generate_X_Y(image_path):\n",
        "  df = generate_df(image_path)\n",
        "  X = [preprocess(cv2.imread(os.path.join(image_path, x),cv2.IMREAD_GRAYSCALE)) for x in df[\"jpg_file\"]]\n",
        "  X = np.array(X)\n",
        "  X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "  X = X.astype('float32') / 255.\n",
        "  return X,df['txt_content']\n",
        "\n",
        "X_teste,labels_teste = generate_X_Y('../dados/CAPTCHA-10k/teste')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(X_teste[0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
        "\n",
        "def psnr(y_true, y_pred):\n",
        "    max_pixel = 1.0\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=max_pixel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "autoencoder = tf.keras.models.load_model('model_MSE_aug_best_unet.tf',custom_objects={\"rmse\": rmse,\"psnr\":psnr})\n",
        "classifier = tf.keras.models.load_model('classifier_pre_trained.tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Setup checkpoint and checkpoint manager\n",
        "checkpoint_dir = './checkpoints'\n",
        "checkpoint = tf.train.Checkpoint(autoencoder=autoencoder, classifier=classifier, optimizer=optimizer)\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)\n",
        "\n",
        "# Restore the latest checkpoint\n",
        "checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
        "\n",
        "if checkpoint_manager.latest_checkpoint:\n",
        "    print(f\"Restored from {checkpoint_manager.latest_checkpoint}\")\n",
        "else:\n",
        "    print(\"Initializing from scratch.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(autoencoder(X_teste[:1])[0],cmap=\"grey\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inference(input_images):\n",
        "    # Forward pass through the autoencoder\n",
        "    autoencoder_output = autoencoder.predict(input_images)\n",
        "    predictions_list = []\n",
        "\n",
        "    interval = [0, 30, 60, 90, 120, 150, 180]\n",
        "\n",
        "    for i in range(len(interval) - 1):\n",
        "        fake_img = autoencoder_output[:, :, interval[i]:interval[i + 1], :]\n",
        "        y_pred = classifier(fake_img, training=False)\n",
        "        predictions_list.append(y_pred)\n",
        "\n",
        "    # Concatenate predictions from all patches\n",
        "    predictions = tf.stack(predictions_list,axis=1)\n",
        "    predictions = tf.argmax(predictions, axis=2)  # Convert to class indices\n",
        "    return predictions.numpy()\n",
        "\n",
        "preds = inference(X_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_tensor = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_preds = vocab_tensor[preds]\n",
        "words = [\"\".join(list(word)) for word in all_preds]\n",
        "df[\"preds\"] = words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_matches(row):\n",
        "    txt_content = row['txt_content']\n",
        "    pred = row['preds']\n",
        "    return sum(1 for a, b in zip(txt_content, pred) if a == b)\n",
        "\n",
        "# Apply the function to each row\n",
        "df['matches'] = df.apply(count_matches, axis=1)\n",
        "df.sort_values(by=\"matches\").head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "match_counts = df['matches'].value_counts().sort_index()\n",
        "\n",
        "# Plot the bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(match_counts.index, match_counts.values, color='skyblue')\n",
        "plt.xlabel('Number of Matches')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Matches per Row')\n",
        "plt.xticks(match_counts.index)  # Ensure x-axis labels match the match counts\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "miss = (df[\"matches\"] != df[\"txt_content\"].str.len()).sum()\n",
        "acc = (len(df) - miss)/len(df)\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate recognition rates\n",
        "max_chars = df['txt_content'].map(len).max()\n",
        "recognition_rates = []\n",
        "\n",
        "for min_correct in range(1, max_chars + 1):\n",
        "    count_correct = df['matches'] >= min_correct\n",
        "    rate = count_correct.mean()\n",
        "    recognition_rates.append(rate)\n",
        "\n",
        "# Plot the recognition rates\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.axhline(y=acc, color='r', linestyle='--', label=f'Overall Accuracy: {acc:.2f}')\n",
        "plt.plot(range(1, max_chars + 1), recognition_rates, marker='o', color='skyblue', label='Recognition Rate')\n",
        "plt.xlabel('Minimum Number of Correct Characters')\n",
        "plt.ylabel('Recognition Rate')\n",
        "plt.title('Recognition Rate vs Minimum Number of Correct Characters')\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.ylim(0, 1)\n",
        "plt.xticks(range(1, max_chars + 1))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
