{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxI4LLcnZqRN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "font_path = '../dados/targa/Targa.ttf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY3XUmVsqEM1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhNVxxbZ6qj",
        "outputId": "1ac5b4e0-1aad-4cd1-f1a3-70c23c374ef6"
      },
      "outputs": [],
      "source": [
        "!wget  -nc https://www.dropbox.com/scl/fi/uaiyxp0t2l8hfcszfadtj/dados.zip?rlkey=lnqcb79vbu8j6cdbfgofogius&dl=1\n",
        "!unzip -n -q dados.zip?rlkey=lnqcb79vbu8j6cdbfgofogius"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-owKNFD5ah24",
        "outputId": "adecb30f-3918-47dd-f02d-b8c94163f530"
      },
      "outputs": [],
      "source": [
        "image_path = '../dados/CAPTCHA-10k/treinamento'\n",
        "def generate_df(image_path):\n",
        "  label_path = '../dados/CAPTCHA-10k/labels10k'\n",
        "\n",
        "  jpg_files = [f for f in os.listdir(image_path) if f.endswith('.jpg')]\n",
        "  jpg_files.sort()\n",
        "  data = []\n",
        "\n",
        "  for jpg_file in jpg_files:\n",
        "      txt_file = os.path.splitext(jpg_file)[0] + '.txt'\n",
        "      txt_file_path = os.path.join(label_path, txt_file)\n",
        "\n",
        "      if os.path.exists(txt_file_path):\n",
        "          with open(txt_file_path, 'r') as file:\n",
        "              txt_content = file.read().strip()\n",
        "\n",
        "          data.append({'jpg_file': jpg_file, 'txt_content': txt_content})\n",
        "  return pd.DataFrame(data)\n",
        "\n",
        "df = generate_df(image_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = [ '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'A', 'B',\n",
        "       'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O',\n",
        "       'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "num_classes = len(vocab)\n",
        "char_to_index = {char: idx for idx, char in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.constant(vocab)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGKSD3tFpvIH"
      },
      "outputs": [],
      "source": [
        "def generate_clean_captcha(text):\n",
        "    # Fixed parameters\n",
        "    size = (180, 50)  # Change size to (height, width)\n",
        "    font_size = 24\n",
        "    num_parts = 6\n",
        "\n",
        "    # Create a blank white image\n",
        "    image = Image.new('L', size, 255)  # 'L' mode for grayscale\n",
        "\n",
        "    # Load the custom font\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "    # Create a drawing context\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Calculate positions for each part\n",
        "    part_width = size[0] / num_parts\n",
        "    horizontal_positions = [int(part_width * i + part_width / 2) for i in range(num_parts)]\n",
        "    horizontal_positions = horizontal_positions[:len(text)]  # Adjust to the length of the text\n",
        "\n",
        "    # Calculate y position to center the text vertically\n",
        "    text_bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    text_height = text_bbox[3] - text_bbox[1]\n",
        "    text_y = (size[1] - text_height) // 2\n",
        "\n",
        "    # Draw each letter at the calculated position\n",
        "    for char, x in zip(text, horizontal_positions):\n",
        "        char_bbox = draw.textbbox((0, 0), char, font=font)\n",
        "        char_width = char_bbox[2] - char_bbox[0]\n",
        "        char_x = x - char_width // 2  # Center the character horizontally within its part\n",
        "        draw.text((char_x, text_y), char, font=font, fill=0)\n",
        "\n",
        "    # Convert to numpy array if needed for further processing with OpenCV\n",
        "    captcha_image = np.array(image)\n",
        "\n",
        "    return captcha_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "  kernel  = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
        "  img     = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "  _, img  = cv2.threshold(img, 90, 255, cv2.THRESH_BINARY)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpd9GwIhpKMe"
      },
      "outputs": [],
      "source": [
        "def generate_X_Y(image_path):\n",
        "  df = generate_df(image_path)\n",
        "  X = [preprocess(cv2.imread(os.path.join(image_path, x),cv2.IMREAD_GRAYSCALE)) for x in df[\"jpg_file\"]]\n",
        "  X = np.array(X)\n",
        "  X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "  Y = np.array([generate_clean_captcha(x[:6]) for x in df[\"txt_content\"]])\n",
        "  X = X.astype('float32') / 255.\n",
        "  Y = (Y.astype('float32') - 127.5)  / 127.5\n",
        "  \n",
        "  return X,Y,df['txt_content']\n",
        "\n",
        "X_train, Y_train,labels_train = generate_X_Y('../dados/CAPTCHA-10k/treinamento')\n",
        "X_val, Y_val,labels_val = generate_X_Y('../dados/CAPTCHA-10k/validacao')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_dataset(X,predictions, labels, batch_size=32):\n",
        "    def encode_labels(labels):\n",
        "        # Create an array to store one-hot encoded labels\n",
        "        encoded_labels = np.zeros((len(labels), 6, num_classes), dtype=np.float32)\n",
        "        \n",
        "        for i, label in enumerate(labels):\n",
        "            for j, char in enumerate(label[:6]):\n",
        "                index = char_to_index.get(char, -1)\n",
        "                encoded_labels[i, j, index] = 1.0\n",
        "        return encoded_labels\n",
        "    \n",
        "    Y = encode_labels(labels)\n",
        "    \n",
        "    # Create TensorFlow datasets from X and Y\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, predictions,Y))\n",
        "\n",
        "    # Shuffle, batch, and prefetch the dataset\n",
        "    buffer_size = len(X)  # Typically set to the size of the dataset\n",
        "    dataset = dataset.shuffle(buffer_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "train_dataset = build_dataset(X_train,Y_train, labels_train)\n",
        "val_dataset = build_dataset(X_val,Y_val, labels_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
        "\n",
        "def psnr(y_true, y_pred):\n",
        "    max_pixel = 1.0\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=max_pixel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "autoencoder = tf.keras.models.load_model('model_MSE_aug_best_unet.tf',custom_objects={\"rmse\": rmse,\"psnr\":psnr})\n",
        "classifier = tf.keras.models.load_model('classifier_pre_trained.tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = autoencoder(X_train[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(a[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(a[0,:,0:30,:],cmap='grey')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab[np.argmax(classifier(a[:,:,0:30,:]))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classification_loss(y_true, y_pred):\n",
        "    # Reshape y_true and y_pred to match the shape expected for loss calculation\n",
        "    return tf.reduce_mean(tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred))\n",
        "\n",
        "def reconstruction_loss(autoencoder_output, captcha_predictions):\n",
        "    # Flatten the outputs and targets\n",
        "    autoencoder_output_flat = tf.keras.backend.flatten(autoencoder_output)\n",
        "    captcha_predictions_flat = tf.keras.backend.flatten(captcha_predictions)\n",
        "    \n",
        "    # Compute MSE loss\n",
        "    return tf.reduce_mean(tf.square(autoencoder_output_flat - captcha_predictions_flat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_tensor = tf.constant(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LAMBDA = 100\n",
        "@tf.function\n",
        "def train_step(input_images, true_images, labels, autoencoder, classifier, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass through the autoencoder\n",
        "        autoencoder_output  = autoencoder(input_images, training=True)\n",
        "        predictions_list = []\n",
        "        true_list = []\n",
        "\n",
        "        c_loss = 0.0\n",
        "        interval = [0,30,60,90,120,150,180]\n",
        "\n",
        "        for i in range(len(interval)-1):\n",
        "            fake_img = autoencoder_output[:,:,interval[i]:interval[i+1],:]\n",
        "            y_pred = classifier(fake_img, training=True)\n",
        "            c_loss += classification_loss(labels[:,i], y_pred)\n",
        "            predictions_list.append(y_pred)\n",
        "            true_list.append(labels[:,i])\n",
        "\n",
        "            # pred = vocab_tensor[tf.argmax(y_pred, axis=-1)[0]]\n",
        "            # act = vocab_tensor[tf.argmax(labels[:, i], axis=-1)[0]]\n",
        "            # tf.print(\"Pred\", pred, \"act\", act, \"c_l\", c_loss)\n",
        "        c_loss /= 6\n",
        "        r_loss = reconstruction_loss(autoencoder_output, true_images)\n",
        "        loss = LAMBDA*r_loss + c_loss\n",
        "        \n",
        "    # Compute gradients\n",
        "    gradients = tape.gradient(loss, autoencoder.trainable_variables + classifier.trainable_variables)\n",
        "    \n",
        "    # Apply gradients\n",
        "    optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables + classifier.trainable_variables))\n",
        "\n",
        "    # Compute accuracy\n",
        "    predictions = tf.concat(predictions_list, axis=0)  # Concatenate predictions from all patches\n",
        "    predictions = tf.argmax(predictions, axis=-1)  # Convert to class indices\n",
        "    predictions = tf.reshape(predictions, [-1])  # Flatten predictions\n",
        "\n",
        "    true = tf.concat(true_list, axis=0)  # Concatenate true from all patches\n",
        "    true = tf.argmax(true, axis=-1)  # Convert to class indices\n",
        "    true = tf.reshape(true, [-1])  # Flatten true\n",
        "\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, true), tf.float32))\n",
        "    return loss, accuracy, r_loss, c_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def validation_step(input_images, true_images, labels, autoencoder, classifier):\n",
        "    # Forward pass through the autoencoder\n",
        "    autoencoder_output = autoencoder(input_images, training=False)\n",
        "    predictions_list = []\n",
        "    true_list = []\n",
        "\n",
        "    c_loss = 0.0\n",
        "    interval = [0, 30, 60, 90, 120, 150, 180]\n",
        "\n",
        "    for i in range(len(interval) - 1):\n",
        "        fake_img = autoencoder_output[:, :, interval[i]:interval[i + 1], :]\n",
        "        y_pred = classifier(fake_img, training=False)\n",
        "        c_loss += classification_loss(labels[:, i], y_pred)\n",
        "        predictions_list.append(y_pred)\n",
        "        true_list.append(labels[:, i])\n",
        "\n",
        "    c_loss /= (len(interval) - 1)\n",
        "    r_loss = reconstruction_loss(autoencoder_output, true_images)\n",
        "    loss = r_loss + LAMBDA * c_loss\n",
        "\n",
        "    # Compute accuracy\n",
        "    predictions = tf.concat(predictions_list, axis=0)  # Concatenate predictions from all patches\n",
        "    predictions = tf.argmax(predictions, axis=-1)  # Convert to class indices\n",
        "    predictions = tf.reshape(predictions, [-1])  # Flatten predictions\n",
        "\n",
        "    true = tf.concat(true_list, axis=0)  # Concatenate true from all patches\n",
        "    true = tf.argmax(true, axis=-1)  # Convert to class indices\n",
        "    true = tf.reshape(true, [-1])  # Flatten true\n",
        "\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, true), tf.float32))\n",
        "    return loss, accuracy, r_loss, c_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "checkpoint_dir = './checkpoints'\n",
        "checkpoint = tf.train.Checkpoint(autoencoder=autoencoder, classifier=classifier, optimizer=optimizer)\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)\n",
        "best_val_accuracy = 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    \n",
        "    # Initialize metrics to accumulate loss and accuracy for training\n",
        "    train_epoch_loss = tf.keras.metrics.Mean()\n",
        "    train_epoch_accuracy = tf.keras.metrics.Mean()\n",
        "    train_epoch_r_loss = tf.keras.metrics.Mean()\n",
        "    train_epoch_c_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "    # Training loop\n",
        "    for (input_images, true_images, labels) in train_dataset:\n",
        "        loss, acc, r_loss, c_loss = train_step(input_images, true_images, labels, autoencoder, classifier, optimizer)\n",
        "        \n",
        "        # Update metrics for training\n",
        "        train_epoch_loss.update_state(loss)\n",
        "        train_epoch_accuracy.update_state(acc)\n",
        "        train_epoch_r_loss.update_state(r_loss)\n",
        "        train_epoch_c_loss.update_state(c_loss)\n",
        "    \n",
        "    # Initialize metrics to accumulate loss and accuracy for validation\n",
        "    val_epoch_loss = tf.keras.metrics.Mean()\n",
        "    val_epoch_accuracy = tf.keras.metrics.Mean()\n",
        "    val_epoch_r_loss = tf.keras.metrics.Mean()\n",
        "    val_epoch_c_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "    # Validation loop\n",
        "    for (input_images, true_images, labels) in val_dataset:\n",
        "        val_loss, val_acc, val_r_loss, val_c_loss = validation_step(input_images, true_images, labels, autoencoder, classifier)\n",
        "        \n",
        "        # Update metrics for validation\n",
        "        val_epoch_loss.update_state(val_loss)\n",
        "        val_epoch_accuracy.update_state(val_acc)\n",
        "        val_epoch_r_loss.update_state(val_r_loss)\n",
        "        val_epoch_c_loss.update_state(val_c_loss)\n",
        "\n",
        "    # Print the mean loss and accuracy for the epoch\n",
        "    print(f\"Training loss: {train_epoch_loss.result().numpy()}  acc: {train_epoch_accuracy.result().numpy()}\")\n",
        "    print(f\"Reconstruction loss: {train_epoch_r_loss.result().numpy()}  Classification loss: {train_epoch_c_loss.result().numpy()}\")\n",
        "    print(\"*\"*80)\n",
        "    # Print the mean loss and accuracy for the validation set\n",
        "    print(f\"Validation loss: {val_epoch_loss.result().numpy()}  acc: {val_epoch_accuracy.result().numpy()}\")\n",
        "    print(f\"Validation Reconstruction loss: {val_epoch_r_loss.result().numpy()}  Validation Classification loss: {val_epoch_c_loss.result().numpy()}\\n\")\n",
        "\n",
        "\n",
        "    # Save the best model based on validation accuracy\n",
        "    if val_epoch_accuracy.result().numpy() > best_val_accuracy:\n",
        "        best_val_accuracy = val_epoch_accuracy.result().numpy()\n",
        "        checkpoint_manager.save()\n",
        "        print(f\"Checkpoint saved at epoch {epoch+1} with validation accuracy: {best_val_accuracy}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
